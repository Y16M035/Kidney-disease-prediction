{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"DataPreparation.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"gKRMj2IgcCu_"},"source":["# Explore and prepare the data"]},{"cell_type":"code","metadata":{"id":"LMq15iwQcCvC","outputId":"10a167c4-fe7d-4fa6-b328-18e3f73d1f64"},"source":["# part after data wrangling. \n","# goal: Transform our datasets to have its ready for the algorithms that are going to learn from the data. \n","# goal of the dataset: We want to predict if the passenger will survive or not based on the other variables. \n","\n","    # we focus on classification problem but all of these is valid for work with other algorithms. \n","    \n","# we use the titanic dataset https://moodle.upm.es/titulaciones/oficiales/course/view.php?id=9326\n","    # train.csv: training dataset. \n","    # test.csv: testing dataset. \n","    \n","# for this day we will work only with train.csv. \n","\n","\n","# 1. libraries: \n","import pandas as pd\n","\n","# 2. read csv file: \n","df = pd.read_csv('train.csv', index_col='PassengerId')\n","# tmp added because it had another path but use just 'train.csv' for the path.\n","df\n","\n","# 3. Understand the attributes/variables of the dataset.\n","    # variable sibSp: Siblings and sposes on board. (understand it by the dataset or the data description)\n","    # Parch: we need to remove 889 row because since age is NaN we can understand if it is a children with\n","       # two parents (sibSp, Parch)\n","      # or a family with two children. \n","    # we need to improve it because skiping the missing values is not always the best option \n","       #(we can omit some meaning if we delete too much rows). \n","    \n","    # Ticket: Ticket number. \n","    # Fare: How much they pay. \n","    # Cabin: Cabin of the passenger. \n","    # Embarked: Port where the passenger embarked. \n","    \n","    # categorical variables vs numerical variables. \n","    \n","    \n","    \n","\n","\n","    \n","    "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 11 columns</p>\n","</div>"],"text/plain":["             Survived  Pclass  \\\n","PassengerId                     \n","1                   0       3   \n","2                   1       1   \n","3                   1       3   \n","4                   1       1   \n","5                   0       3   \n","...               ...     ...   \n","887                 0       2   \n","888                 1       1   \n","889                 0       3   \n","890                 1       1   \n","891                 0       3   \n","\n","                                                          Name     Sex   Age  \\\n","PassengerId                                                                    \n","1                                      Braund, Mr. Owen Harris    male  22.0   \n","2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n","3                                       Heikkinen, Miss. Laina  female  26.0   \n","4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n","5                                     Allen, Mr. William Henry    male  35.0   \n","...                                                        ...     ...   ...   \n","887                                      Montvila, Rev. Juozas    male  27.0   \n","888                               Graham, Miss. Margaret Edith  female  19.0   \n","889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n","890                                      Behr, Mr. Karl Howell    male  26.0   \n","891                                        Dooley, Mr. Patrick    male  32.0   \n","\n","             SibSp  Parch            Ticket     Fare Cabin Embarked  \n","PassengerId                                                          \n","1                1      0         A/5 21171   7.2500   NaN        S  \n","2                1      0          PC 17599  71.2833   C85        C  \n","3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n","4                1      0            113803  53.1000  C123        S  \n","5                0      0            373450   8.0500   NaN        S  \n","...            ...    ...               ...      ...   ...      ...  \n","887              0      0            211536  13.0000   NaN        S  \n","888              0      0            112053  30.0000   B42        S  \n","889              1      2        W./C. 6607  23.4500   NaN        S  \n","890              0      0            111369  30.0000  C148        C  \n","891              0      0            370376   7.7500   NaN        Q  \n","\n","[891 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"4kKPNXMucCvD","outputId":"9f388a74-82f9-4290-ccb0-f1b1f51b4b1b"},"source":["# the first thing we are going to do is to impute missing values: \n","df.isnull()\n","# this is not a good summary, for improve it we use the method any(): \n","df.isnull().any()\n","# we can see which variables have missing values. "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Survived    False\n","Pclass      False\n","Name        False\n","Sex         False\n","Age          True\n","SibSp       False\n","Parch       False\n","Ticket      False\n","Fare        False\n","Cabin        True\n","Embarked     True\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"iWlW_bqNcCvD","outputId":"69bc6e3b-d1e0-47cc-eec8-0717662b8b7a"},"source":["# we have to do something with Age, Cabin, Embarked. \n","# we need to improve the missing values. \n","\n","# which variables are not relevant? \n","    # to discard a variable you need to be sure that is irrelevant for the goal we have\n","      # (predict if the passenger will survive or not based on the other variables). \n","    \n","        # is the name relevant? is very difficult to use the name because is not relevant. \n","          # it could be used by we need NLP. The effort that not compensate the info we can extract\n","          # from the name in this case. When we mix letters and numbers (text value). \n","          # categorical values: Can only take some values like an enum. When it has text but is not categorical are\n","          # text values and then we need NLP. \n","        \n","        # then we can remove name, ticket and cabin. \n","        \n","        \n","df.pop('Name')\n","df.pop('Ticket')\n","df.pop('Cabin')\n","# pop modify the dataframe. With drop you need to use the argument \"inplace=true\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PassengerId\n","1       NaN\n","2       C85\n","3       NaN\n","4      C123\n","5       NaN\n","       ... \n","887     NaN\n","888     B42\n","889     NaN\n","890    C148\n","891     NaN\n","Name: Cabin, Length: 891, dtype: object"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"hguFDTXrcCvE"},"source":["# now we are going to split the dataframe in categorical and numerical\n","# \n","df.dtypes\n","\n","cat_mask = (df.dtypes==object) \n","# return the columns that are not numerical encoded.\n","cat_cols = df.columns[cat_mask].tolist()\n","# list with the name of the columns that fulfills the mask. \n","df_cat = df[cat_cols] # then we obtain only the categorical columns\n","\n","df_num = df.drop(cat_cols, axis=1)\n","# so we have in df_cat the categorical columns and in df_num the numerical columns. \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0D0paYjcCvE","outputId":"522bc772-ac4f-4492-dc04-d137ab799205"},"source":["\n","from sklearn.impute import SimpleImputer\n","# with a simple inputer we can input the missing values by statistical summary of variables. \n","# to input the port into the person. If you don't have the value where the person embarked? \n","    # Use classification methods using the values of the other variables to impute this. \n","    # we use a simple method that is the most frequent. \n","    \n","imp_cat = SimpleImputer(strategy='most_frequent')\n","\n"," \n","#imp_cat.fit\n","# we are going to learn the function that transform our data. \n","# impute the missing values with the most: \n","df_cat = pd.DataFrame(imp_cat.fit_transform(df_cat), \n","            columns=df_cat.columns, index=df_cat.index)\n","df_cat"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>male</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>female</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>female</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>female</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>male</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>male</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>female</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>female</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>male</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>male</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 2 columns</p>\n","</div>"],"text/plain":["                Sex Embarked\n","PassengerId                 \n","1              male        S\n","2            female        C\n","3            female        S\n","4            female        S\n","5              male        S\n","...             ...      ...\n","887            male        S\n","888          female        S\n","889          female        S\n","890            male        C\n","891            male        Q\n","\n","[891 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2zxURDyecCvE","outputId":"baa2261c-0b6c-4f98-d6ec-d67a3961d5ee"},"source":["df_cat.isnull().any()\n","# to check we don't have missing values\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sex         False\n","Embarked    False\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"QcNXqtBfcCvF","outputId":"3adf4187-044c-4fd3-835e-5f93caaabac2"},"source":["# most of the algorithms can not work with text values, so we are going to transform them into numerical \n","  # values. \n","# we will use a Label Encoder for each column (we apply a different transformation for each column). We create a\n","  # dictionary of Label Encoder: \n","    \n","from sklearn import preprocessing\n","from collections import defaultdict\n","\n","d = defaultdict(preprocessing.LabelEncoder) # dictionary of Label Encoder. Two different entries (sex and embarked)\n","\n","# to transform the dataset we are going to apply a lambda function (data wrangling lesson) to the dataframe: \n","\n","df_cat_le = df_cat.apply(lambda col: d[col.name].fit_transform(col))\n","# we apply to the df a function (fit_transform) but moreover the function will be different for each column. The function depends\n","# on the entry of the dictionary, so I have a label encoder for each entry. \n","# lambda function allow us to use a different Label Encoder function to each entry. \n","\n","# this is enough for transform our data.\n","df_cat_le\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 2 columns</p>\n","</div>"],"text/plain":["             Sex  Embarked\n","PassengerId               \n","1              1         2\n","2              0         0\n","3              0         2\n","4              0         2\n","5              1         2\n","...          ...       ...\n","887            1         2\n","888            0         2\n","889            0         2\n","890            1         0\n","891            1         1\n","\n","[891 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"6Sb7UxwucCvF"},"source":["# we transform text and categorical values in numerical values. \n","    # but which is the problem? \n","# we are introducing an order that before not existed. \n","\n","'''\n","If we consider: \n","port A codified as 0\n","port B codified as 1\n","port C codifed as 2\n","\n","If we treat them as numerical values we are introducing an order that was not desired. \n","For solve this we need one-hot encoding. \n","\n","C  M  S\n","1  0  0\n","0  1  0\n","0  0  1\n","\n","Doing this we are not introducing an order. \n","\n","It depends on the data if the data have an order decided then is correct to use label encoding: \n","Example: \n","\n","First. 0\n","Second. 1\n","Third. 2\n","\n","Here the order is desired so it makes sense to use label encoding rather than one-hot encoding. \n","\n","'''\n","\n","# to solve this we can use a different encoder that is called \"one-hot encoder\". \n","# first apply an inverse transformation (undo the transformation we did)\n","aux = df_cat_le.apply(lambda col: d[col.name].inverse_transform(col))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"me0FxClGcCvG"},"source":["# one-hot encoding. \n","# draw 1 OneNote. \n","# disadvantage: Just only one column could be 1, but is better than introduce an order in a not ordered variable before\n","   # (last transformation). \n","    \n","# we need to split this df in two one for transform with label encoder(sex) and the other with one-hot encoder. \n","# for simplicity we just only use one-hot encoder: \n","ohe = preprocessing.OneHotEncoder(sparse=False)\n","df_cat_ohe = pd.DataFrame(ohe.fit_transform(df_cat), \n","            columns=ohe.get_feature_names(df_cat.columns.tolist()),\n","            index=df_cat.index) # preserve the structure of the df (changing it). \n","# get_feature_names: return the actual names of the columns. \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZizS0BoKcCvH","outputId":"19437b80-4c5e-41c9-8bdd-910fbea8973f"},"source":["df_cat_ohe\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 5 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n","PassengerId                                                          \n","1                   0.0       1.0         0.0         0.0         1.0\n","2                   1.0       0.0         1.0         0.0         0.0\n","3                   1.0       0.0         0.0         0.0         1.0\n","4                   1.0       0.0         0.0         0.0         1.0\n","5                   0.0       1.0         0.0         0.0         1.0\n","...                 ...       ...         ...         ...         ...\n","887                 0.0       1.0         0.0         0.0         1.0\n","888                 1.0       0.0         0.0         0.0         1.0\n","889                 1.0       0.0         0.0         0.0         1.0\n","890                 0.0       1.0         1.0         0.0         0.0\n","891                 0.0       1.0         0.0         1.0         0.0\n","\n","[891 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"y65SormycCvH","outputId":"56bcd8bc-db63-47cf-b5a6-1433131efd96"},"source":["# we have the categorical variables transformed. \n","# now we are going to improve the numerical values: \n","  # now we use Regression Methods.\n","    # we use the mean method\n","imp_num = SimpleImputer(strategy='mean')\n","df_num = pd.DataFrame(imp_num.fit_transform(df_num), \n","                     columns=df_num.columns, \n","                     index=df_num.index)\n","df_num\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>22.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>38.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>35.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>35.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>27.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0000</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>19.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>29.699118</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>23.4500</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>32.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 6 columns</p>\n","</div>"],"text/plain":["             Survived  Pclass        Age  SibSp  Parch     Fare\n","PassengerId                                                    \n","1                 0.0     3.0  22.000000    1.0    0.0   7.2500\n","2                 1.0     1.0  38.000000    1.0    0.0  71.2833\n","3                 1.0     3.0  26.000000    0.0    0.0   7.9250\n","4                 1.0     1.0  35.000000    1.0    0.0  53.1000\n","5                 0.0     3.0  35.000000    0.0    0.0   8.0500\n","...               ...     ...        ...    ...    ...      ...\n","887               0.0     2.0  27.000000    0.0    0.0  13.0000\n","888               1.0     1.0  19.000000    0.0    0.0  30.0000\n","889               0.0     3.0  29.699118    1.0    2.0  23.4500\n","890               1.0     1.0  26.000000    0.0    0.0  30.0000\n","891               0.0     3.0  32.000000    0.0    0.0   7.7500\n","\n","[891 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"sNxzZhMWcCvI","outputId":"1851c5f1-24f3-49aa-d78a-29fca8d6cae2"},"source":["# in row 889 we can see that has been imputed by the other values. \n","# check if we have missing values. We must not have it. \n","df_num.isnull().any()\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Survived    False\n","Pclass      False\n","Age         False\n","SibSp       False\n","Parch       False\n","Fare        False\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"yLCM88XLcCvI","outputId":"a0b37134-440a-4fe9-f8e1-59afb18f7420"},"source":["# Since we have splited the dataframes now we are going to merge them into one df. \n","\n","df_preprocessed = pd.merge(left=df_cat_ohe, \n","                           right=df_num,\n","                           on='PassengerId')\n","df_preprocessed\n","# since we are combining the two dataframes we need to specify by which column we want to merge the values. \n","   # in this case using the index. (means: merge the values of passenger_Id=1 from the left \n","    # with the values of passenger_id=1 from the right)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>22.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>38.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>35.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>35.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>27.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0000</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>19.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>29.699118</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>23.4500</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>32.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 11 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n","PassengerId                                                             \n","1                   0.0       1.0         0.0         0.0         1.0   \n","2                   1.0       0.0         1.0         0.0         0.0   \n","3                   1.0       0.0         0.0         0.0         1.0   \n","4                   1.0       0.0         0.0         0.0         1.0   \n","5                   0.0       1.0         0.0         0.0         1.0   \n","...                 ...       ...         ...         ...         ...   \n","887                 0.0       1.0         0.0         0.0         1.0   \n","888                 1.0       0.0         0.0         0.0         1.0   \n","889                 1.0       0.0         0.0         0.0         1.0   \n","890                 0.0       1.0         1.0         0.0         0.0   \n","891                 0.0       1.0         0.0         1.0         0.0   \n","\n","             Survived  Pclass        Age  SibSp  Parch     Fare  \n","PassengerId                                                      \n","1                 0.0     3.0  22.000000    1.0    0.0   7.2500  \n","2                 1.0     1.0  38.000000    1.0    0.0  71.2833  \n","3                 1.0     3.0  26.000000    0.0    0.0   7.9250  \n","4                 1.0     1.0  35.000000    1.0    0.0  53.1000  \n","5                 0.0     3.0  35.000000    0.0    0.0   8.0500  \n","...               ...     ...        ...    ...    ...      ...  \n","887               0.0     2.0  27.000000    0.0    0.0  13.0000  \n","888               1.0     1.0  19.000000    0.0    0.0  30.0000  \n","889               0.0     3.0  29.699118    1.0    2.0  23.4500  \n","890               1.0     1.0  26.000000    0.0    0.0  30.0000  \n","891               0.0     3.0  32.000000    0.0    0.0   7.7500  \n","\n","[891 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"Tx6iukOucCvI"},"source":["# then we have the same df we had at the first step but without missing values. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRZHJagLcCvJ","outputId":"fa5024ef-efbd-430c-a679-debb84753fb0"},"source":["# let's continue with feature selection = select the relevant values that need to be correlated with survived. \n","# there are methods that allow us to know which values are the best correlated for that. \n","\n","class_col = df_preprocessed.pop('Survived')\n","# create the class_col by the target class.\n","from sklearn.feature_selection import SelectKBest # select the variables that are the most correlated with the target variable. \n","# it perform also a chi-square test for doing it. \n","from sklearn.feature_selection import chi2\n","\n","fs_k_best_chi2 = SelectKBest(chi2, k=4) # select the four most relevant variables for the problem\n","fs_k_best_chi2.fit(df_preprocessed, class_col) # class_col: target variable (supervised learning). This only\n","# fits the algorithm. \n","# now we are going to see the support of each column: \n","col_filter = fs_k_best_chi2.get_support()\n","print(col_filter)\n","# say which columns we will need to preserve."],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ True  True False False False  True False False False  True]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"16tecfJzcCvK","outputId":"1db3dbf2-15a6-4fe2-bbb9-c19238ed16f9"},"source":["# so that we can filter this columns: \n","df_k_best_chi2 = df_preprocessed.iloc[:, col_filter]\n","df_k_best_chi2 \n","# the most relevant columns by a chi-square test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Pclass</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>13.0000</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>23.4500</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 4 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Pclass     Fare\n","PassengerId                                       \n","1                   0.0       1.0     3.0   7.2500\n","2                   1.0       0.0     1.0  71.2833\n","3                   1.0       0.0     3.0   7.9250\n","4                   1.0       0.0     1.0  53.1000\n","5                   0.0       1.0     3.0   8.0500\n","...                 ...       ...     ...      ...\n","887                 0.0       1.0     2.0  13.0000\n","888                 1.0       0.0     1.0  30.0000\n","889                 1.0       0.0     3.0  23.4500\n","890                 0.0       1.0     1.0  30.0000\n","891                 0.0       1.0     3.0   7.7500\n","\n","[891 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"LByYlSAfcCvK","outputId":"52764421-1dc1-481c-fa52-5395ecd0303f"},"source":["# Select a set of relevant features: \n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import mutual_info_classif\n","# now we use another method: \n","fs_k_best_mi = SelectKBest(mutual_info_classif, k=4) # select the four most relevant variables for the problem\n","fs_k_best_mi.fit(df_preprocessed, class_col) # class_col: target variable (supervised learning). This only\n","# fits the algorithm. \n","# now we are going to see the support of each column: \n","col_filter = fs_k_best_mi.get_support()\n","print(col_filter)\n","# say which columns we will need to preserve.\n","\n","# so that we can filter this columns: \n","df_k_best_mi = df_preprocessed.iloc[:, col_filter]\n","df_k_best_mi \n","# the most relevant columns by a chi-square test\n","\n","# investigate wraper broader approach\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ True  True False False False  True False False False  True]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Pclass</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>13.0000</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>23.4500</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 4 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Pclass     Fare\n","PassengerId                                       \n","1                   0.0       1.0     3.0   7.2500\n","2                   1.0       0.0     1.0  71.2833\n","3                   1.0       0.0     3.0   7.9250\n","4                   1.0       0.0     1.0  53.1000\n","5                   0.0       1.0     3.0   8.0500\n","...                 ...       ...     ...      ...\n","887                 0.0       1.0     2.0  13.0000\n","888                 1.0       0.0     1.0  30.0000\n","889                 1.0       0.0     3.0  23.4500\n","890                 0.0       1.0     1.0  30.0000\n","891                 0.0       1.0     3.0   7.7500\n","\n","[891 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"JPdkfT49cCvL"},"source":["'''\n","DOUBTS: \n","How do you select the number or varables? trial and error.\n","\n","The columns may be random selected (sklearn introduce a randomization) example: \n","sometimes are \"sex_female\"\n","sex_male\", \"Pclass\", \"Fare\" and other times are other variables. \n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1FaBPKlVcCvM"},"source":["# Learn the model:\n","\n","From Slide 17. \n","\n","Hands on from slide 1 hands-on part\n"]},{"cell_type":"code","metadata":{"id":"lBgyva-KcCvM","outputId":"ac7539ba-d0d2-43d4-ee13-b76d1efc56b7"},"source":["df_preprocessed # Starting point. "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>22.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>7.2500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>38.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>71.2833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.9250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>35.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>53.1000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>35.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>27.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0000</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>19.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>29.699118</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>23.4500</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>26.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.0000</td>\n","    </tr>\n","    <tr>\n","      <th>891</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>32.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows × 10 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass  \\\n","PassengerId                                                                     \n","1                   0.0       1.0         0.0         0.0         1.0     3.0   \n","2                   1.0       0.0         1.0         0.0         0.0     1.0   \n","3                   1.0       0.0         0.0         0.0         1.0     3.0   \n","4                   1.0       0.0         0.0         0.0         1.0     1.0   \n","5                   0.0       1.0         0.0         0.0         1.0     3.0   \n","...                 ...       ...         ...         ...         ...     ...   \n","887                 0.0       1.0         0.0         0.0         1.0     2.0   \n","888                 1.0       0.0         0.0         0.0         1.0     1.0   \n","889                 1.0       0.0         0.0         0.0         1.0     3.0   \n","890                 0.0       1.0         1.0         0.0         0.0     1.0   \n","891                 0.0       1.0         0.0         1.0         0.0     3.0   \n","\n","                   Age  SibSp  Parch     Fare  \n","PassengerId                                    \n","1            22.000000    1.0    0.0   7.2500  \n","2            38.000000    1.0    0.0  71.2833  \n","3            26.000000    0.0    0.0   7.9250  \n","4            35.000000    1.0    0.0  53.1000  \n","5            35.000000    0.0    0.0   8.0500  \n","...                ...    ...    ...      ...  \n","887          27.000000    0.0    0.0  13.0000  \n","888          19.000000    0.0    0.0  30.0000  \n","889          29.699118    1.0    2.0  23.4500  \n","890          26.000000    0.0    0.0  30.0000  \n","891          32.000000    0.0    0.0   7.7500  \n","\n","[891 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ObaSMD1PcCvN","outputId":"acaf4c1b-3b01-4c0e-a8db-04b670fd5361"},"source":["# Slide 2: \n","\n","from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(df_preprocessed, class_col, \n","                                                    test_size = 0.3, random_state=1)\n","x_train\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>115</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>17.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.4583</td>\n","    </tr>\n","    <tr>\n","      <th>875</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>28.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>24.0000</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>29.699118</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.8958</td>\n","    </tr>\n","    <tr>\n","      <th>877</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>20.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.8458</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>29.699118</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>716</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>19.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.6500</td>\n","    </tr>\n","    <tr>\n","      <th>768</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>30.500000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.7500</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>21.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>73.5000</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>29.699118</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.5500</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>21.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>8.0500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>623 rows × 10 columns</p>\n","</div>"],"text/plain":["             Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass  \\\n","PassengerId                                                                     \n","115                 1.0       0.0         1.0         0.0         0.0     3.0   \n","875                 1.0       0.0         1.0         0.0         0.0     2.0   \n","77                  0.0       1.0         0.0         0.0         1.0     3.0   \n","877                 0.0       1.0         0.0         0.0         1.0     3.0   \n","675                 0.0       1.0         0.0         0.0         1.0     2.0   \n","...                 ...       ...         ...         ...         ...     ...   \n","716                 0.0       1.0         0.0         0.0         1.0     3.0   \n","768                 1.0       0.0         0.0         1.0         0.0     3.0   \n","73                  0.0       1.0         0.0         0.0         1.0     2.0   \n","236                 1.0       0.0         0.0         0.0         1.0     3.0   \n","38                  0.0       1.0         0.0         0.0         1.0     3.0   \n","\n","                   Age  SibSp  Parch     Fare  \n","PassengerId                                    \n","115          17.000000    0.0    0.0  14.4583  \n","875          28.000000    1.0    0.0  24.0000  \n","77           29.699118    0.0    0.0   7.8958  \n","877          20.000000    0.0    0.0   9.8458  \n","675          29.699118    0.0    0.0   0.0000  \n","...                ...    ...    ...      ...  \n","716          19.000000    0.0    0.0   7.6500  \n","768          30.500000    0.0    0.0   7.7500  \n","73           21.000000    0.0    0.0  73.5000  \n","236          29.699118    0.0    0.0   7.5500  \n","38           21.000000    0.0    0.0   8.0500  \n","\n","[623 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"CyDg7j-NcCvN"},"source":["The rows have a random order. \n","We have a subset of the original dataset 891 * 0.7 = 623.7 (rounds to the floor value)."]},{"cell_type":"code","metadata":{"id":"j9q5H-ThcCvN","outputId":"f0fc46d7-1f29-449e-8f68-176befcc14ac"},"source":["# Learn a decission tree (sLIDE 3)\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tree = DecisionTreeClassifier(random_state=1)\n","tree.fit(x_train, y_train)\n","# We are ready to make predictions (learnt the decission tree)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(random_state=1)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Hi_NiS7rcCvO","outputId":"0629ca24-7b04-4d76-9081-35bc603a04d3"},"source":["# How to make predictions? \n","y_pred = tree.predict(x_test)\n","y_pred"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n","       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n","       0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n","       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n","       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n","       1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","       0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n","       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n","       1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n","       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n","       0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n","       1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"lurauG0ZcCvO","outputId":"5e833f6a-c05e-44ab-d5bf-80296912d4b9"},"source":["# print the values that should be predicted and the values that we have predicted: \n","# To check the errors of the algorithm. \n","\n","print(y_test)\n","print(y_pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PassengerId\n","863    1.0\n","224    0.0\n","85     1.0\n","681    0.0\n","536    1.0\n","      ... \n","248    1.0\n","552    0.0\n","240    0.0\n","485    1.0\n","93     0.0\n","Name: Survived, Length: 268, dtype: float64\n","[1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n"," 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n"," 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0.\n"," 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n"," 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n"," 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0.\n"," 0. 0. 0. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JpxoCCqKcCvO","outputId":"48877791-6488-4e41-af75-118e9839e2f3"},"source":["# Confussion matrix: \n","\n","from sklearn.metrics import confusion_matrix\n","\n","conf = pd.DataFrame(confusion_matrix(y_test, y_pred),\n","            columns = [\"Predicted 0\", \"Predicted 1\"], \n","            index = [\"True 0\", \"True 1\"])\n","conf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Predicted 0</th>\n","      <th>Predicted 1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>True 0</th>\n","      <td>127</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>True 1</th>\n","      <td>43</td>\n","      <td>72</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Predicted 0  Predicted 1\n","True 0          127           26\n","True 1           43           72"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"HK5J4B80cCvO","outputId":"469953f1-3594-4256-e9b9-abeec8f49a2c"},"source":["# Acuracy metrics: \n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))\n","\n","'''\n","    The accuracy give the % of samples that are good predicted. \n","    Review how interpret the results. \n","\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.83      0.79       153\n","         1.0       0.73      0.63      0.68       115\n","\n","    accuracy                           0.74       268\n","   macro avg       0.74      0.73      0.73       268\n","weighted avg       0.74      0.74      0.74       268\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gy-CqWQecCvP","outputId":"16749fd0-93ea-4369-87e1-0cc289bd835e"},"source":["# Modificating some parameters because the accuracy is not good: \n","# Decission tree tend to overfit the model respect the data. \n","# To try to improve it: \n","\n","tree = DecisionTreeClassifier(random_state=1, max_depth=4)\n","tree.fit(x_train, y_train)\n","y_pred = tree.predict(x_test)\n","\n","conf2 = pd.DataFrame(confusion_matrix(y_test, y_pred),\n","            columns = [\"Predicted 0\", \"Predicted 1\"], \n","            index = [\"True 0\", \"True 1\"])\n","conf2\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Predicted 0</th>\n","      <th>Predicted 1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>True 0</th>\n","      <td>142</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>True 1</th>\n","      <td>49</td>\n","      <td>66</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Predicted 0  Predicted 1\n","True 0          142           11\n","True 1           49           66"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"_ByqyBpPcCvP","outputId":"b895ef8f-d398-4253-cba9-56af1f5f860c"},"source":["print(y_test)\n","print(y_pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PassengerId\n","863    1.0\n","224    0.0\n","85     1.0\n","681    0.0\n","536    1.0\n","      ... \n","248    1.0\n","552    0.0\n","240    0.0\n","485    1.0\n","93     0.0\n","Name: Survived, Length: 268, dtype: float64\n","[1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n"," 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n"," 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n"," 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n"," 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n"," 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n"," 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jo_d1Sj6cCvP","outputId":"aacc736e-ee87-4998-b4a8-7121f9de87e5"},"source":["print(classification_report(y_test, y_pred))\n","\n","# Use parameters of slide 3. "],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.93      0.83       153\n","         1.0       0.86      0.57      0.69       115\n","\n","    accuracy                           0.78       268\n","   macro avg       0.80      0.75      0.76       268\n","weighted avg       0.79      0.78      0.77       268\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IWKvXqk4cCvP","outputId":"21bcf344-d6f4-4fc0-de44-d8538a3903b5"},"source":["tree = DecisionTreeClassifier(random_state=1, max_depth=4, min_samples_split=5,\n","                             min_samples_leaf=3)\n","tree.fit(x_train, y_train)\n","y_pred = tree.predict(x_test)\n","\n","print(classification_report(y_test, y_pred))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.93      0.83       153\n","         1.0       0.86      0.57      0.69       115\n","\n","    accuracy                           0.78       268\n","   macro avg       0.80      0.75      0.76       268\n","weighted avg       0.79      0.78      0.77       268\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lcyh2MCZcCvP"},"source":["Doubts: \n","    \n","    Is it good to use DT for regressions? \n","    Is better to use Regression Trees but are not the same as DT. "]},{"cell_type":"markdown","metadata":{"id":"nRig3HxzcCvQ"},"source":["## Other models: \n","### Ensamble learning: \n","\n","Consists on learning multiple models to solve a problem. \n","\n","Slide 8"]},{"cell_type":"code","metadata":{"id":"Cg8OlvvXcCvQ"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(n_estimators=100, random_state=1)\n","rf.fit(x_train, y_train)\n","y_pred_rf = rf.predict(x_test)\n","\n","# Follow the code of the slide. \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Juuk01L8cCvQ"},"source":["from sklearn.svm import SVC\n","\n","svm = SVC(C=10)\n","svm.fit(x_train, y_train)\n","\n","\n","'''\n","    Why the accuracy decrease? \n","    The features are not in the same scale.\n","\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKIGO0HNcCvQ"},"source":["# Remember we can not scale variables that are not numerical. \n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","mms = MinMaxScaler()\n","df_num_sc = pd.DataFrame(mms.fit_transform(df_num), columns = df_num.columns,\n","                         index = df_num.index)\n","# we put in a df for maintain the names of columns and number of rows. \n","\n","df_preprocessed_sc = pd.merge(left=df_cat_ohe, right=df_num_sc, on='PassengerId')\n","\n","x_train_sc, x_test_sc, y_train_sc, y_test_sc = train_test_split(df_preprocessed_sc, class_col,\n","                                                               test_size=0.3, random_state=1)\n","\n","print(classification_report(y_test_sc, y_pred_sc))\n","\n","conf3 = pd.DataFrame(confusion_matrix(y_test_sc, y_pred_sc),\n","                    columns=['Predicted 0', 'Predicted 1'], \n","                    rows = ['True 0', 'True 1'])\n","conf3\n","\n","\n","# The results should be sth as in slide 15.\n","# The accuracy can not be 1 (if it is you have an error). "],"execution_count":null,"outputs":[]}]}